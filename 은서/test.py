import os
import json
import math
import random
import argparse
import numpy as np
from glob import glob
from typing import List, Tuple, Dict, Any
from PIL import Image

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from tqdm import tqdm
import pandas as pd
import torchvision.transforms as T 

# --- [1. code444.pyì—ì„œ í•„ìš”í•œ ìš”ì†Œ import] ---
from code444 import (
    seed_everything,
    BestVLM,        # ğŸ’¡ code444.pyì˜ ëª¨ë¸ í´ë˜ìŠ¤
    CFG,
    box_cxcywh_to_xyxy,
    read_json       
)
from transformers import CLIPProcessor 

# --- [2. ëª¨ë¸ ë¡œë“œ Helper (code444.py í˜¸í™˜)] ---
def _load_model_from_ckpt(ckpt_path: str, device: torch.device):
    """ ì €ì¥ëœ ì²´í¬í¬ì¸íŠ¸(.pth)ì—ì„œ ëª¨ë¸ê³¼ ì„¤ì •ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤. """
    ckpt = torch.load(ckpt_path, map_location=device)
    
    clip_model_name = ckpt.get("clip_model_name", CFG.CLIP_MODEL_NAME)
    dim = ckpt.get("dim", CFG.DIM)
    img_size = ckpt.get("img_size", CFG.IMG_SIZE)
    no_pretrain = ckpt.get("no_pretrain", False)

    model = BestVLM(clip_model_name=clip_model_name,
                         dim=dim,
                         pretrained_backbone=not no_pretrain,
                         img_size=img_size).to(device)
    
    clip_processor = CLIPProcessor.from_pretrained(clip_model_name)
    model.load_state_dict(ckpt["model_state"])
    model.eval() 
    
    print(f"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {ckpt_path}")
    return model, clip_processor, img_size

# --- [3. ğŸ’¡ [í•µì‹¬] Test ë°ì´í„° ì „ìš© Dataset í´ë˜ìŠ¤ (CSV ê¸°ë°˜) ğŸ’¡] ---
class TestDSetVLM(Dataset):
    """
    Test ë°ì´í„°ì…‹ ë¡œë” (sample_submission.csv ì˜ ìˆœì„œë¥¼ ë³´ì¥)
    """
    def __init__(self, submission_df: pd.DataFrame, jpg_dir: str, 
                 clip_processor: CLIPProcessor, 
                 max_txt_len: int = 77, img_size: int = 512):
        
        self.items = []
        self.processor = clip_processor
        self.max_txt_len = max_txt_len
        
        self.img_transform = T.Compose([
            T.Resize((img_size, img_size)),
            T.ToTensor()
        ])
        
        print("Test ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘... (sample_submission.csv  ê¸°ë°˜)")
        
        for idx, row in tqdm(submission_df.iterrows(), total=len(submission_df), desc="Test ìƒ˜í”Œ ë§¤ì¹­"):
            query_id = row["query_id"]
            query_text = row["query_text"]
            
            # 1. ğŸ’¡ [í•µì‹¬] query_id ë¡œë¶€í„° ì´ë¯¸ì§€ íŒŒì¼ëª…(MI2...) ì¶”ë¡ 
            # ì˜ˆ: MI3_240819_TY1_0011_1_V02-8_1 -> MI2_240819_TY1_0011_1.jpg
            parts = query_id.split('_')
            if len(parts) < 5:
                print(f"ê²½ê³ : ì˜ˆê¸°ì¹˜ ì•Šì€ query_id í˜•ì‹: {query_id}")
                continue
                
            base_name = "_".join(parts[:5]) # 'MI3_240819_TY1_0011_1'
            img_name = base_name.replace("MI3", "MI2") + ".jpg" # 'MI2_...jpg'
            
            img_path = os.path.join(jpg_dir, img_name)

            if not os.path.exists(img_path):
                # print(f"ê²½ê³ : {img_path} ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (Query ID: {query_id})")
                continue
                
            self.items.append({
                "img_path": img_path,
                "query_text": query_text,
                "query_id": query_id,
            })
        
        print(f"ğŸ“Œ [Test] ìµœì¢… ë§¤ì¹­ëœ ìƒ˜í”Œ ìˆ˜: {len(self.items)}")

    def __len__(self):
        return len(self.items)

    def __getitem__(self, idx: int) -> Dict[str, Any]:
        it = self.items[idx]
        
        try:
            img = Image.open(it["img_path"]).convert("RGB") 
        except Exception as e:
            return None 
        W, H = img.size
        
        qtxt = it["query_text"]
        
        txt_encoding = self.processor(
            text=qtxt,
            images=None, 
            return_tensors="pt",
            padding="max_length",
            truncation=True,
            max_length=self.max_txt_len
        )
        
        img_t = self.img_transform(img)

        sample = {
            "input_ids": txt_encoding["input_ids"].squeeze(0),
            "attention_mask": txt_encoding["attention_mask"].squeeze(0),
            "pixel_values": img_t, 
            "query_id": it["query_id"],
            "query_text": it["query_text"],
            "orig_size": (W, H),
        }
        return sample

def collate_fn_test(batch: List[Dict[str, Any]]):
    """ Test ë°ì´í„° ì „ìš© collate_fn """
    batch = [b for b in batch if b is not None]
    if not batch:
        return None, None, None, None

    input_ids = torch.stack([b["input_ids"] for b in batch])
    attention_mask = torch.stack([b["attention_mask"] for b in batch])
    pixel_values = torch.stack([b["pixel_values"] for b in batch])
    
    meta = [
        {
            "query_id": b["query_id"], 
            "query_text": b["query_text"],
            "orig_size": b["orig_size"]
        }
        for b in batch
    ]
    return pixel_values, input_ids, attention_mask, meta

# --- [4. ë©”ì¸ ì¶”ë¡  ë£¨í”„] ---
def predict_loop(args):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")

    model, clip_processor, img_size = _load_model_from_ckpt(args.ckpt, device)

    # ğŸ’¡ [í•µì‹¬] sample_submission.csv  ë¡œë“œ
    sub_df = pd.read_csv(args.submission_csv)
    
    # ğŸ’¡ [í•µì‹¬] DataFrameì„ ê¸°ë°˜ìœ¼ë¡œ TestDSetVLM ìƒì„±
    test_ds = TestDSetVLM(sub_df, args.jpg_dir, clip_processor=clip_processor,
                         img_size=img_size)
    
    test_dl = DataLoader(test_ds, batch_size=args.batch_size, shuffle=False,
                          num_workers=args.num_workers, collate_fn=collate_fn_test)

    # ğŸ’¡ [í•µì‹¬] ì˜ˆì¸¡ ê²°ê³¼ë¥¼ {query_id: prediction} ë”•ì…”ë„ˆë¦¬ì— ì €ì¥
    predictions = {}
    
    with torch.no_grad(): 
        loop = tqdm(test_dl, desc="Generating Predictions", leave=True)
        
        for pixel_values, input_ids, attention_mask, meta in loop:
            if pixel_values is None: continue 
            
            pixel_values = pixel_values.to(device)
            input_ids = input_ids.to(device)
            attention_mask = attention_mask.to(device)
            
            pred_norm = model(pixel_values, input_ids, attention_mask) 

            for i in range(pred_norm.size(0)):
                W, H = meta[i]["orig_size"] 
                
                cx, cy, nw, nh = [float(v) for v in pred_norm[i].cpu().numpy().tolist()]
                
                pred_x = (cx - nw / 2.0) * W
                pred_y = (cy - nh / 2.0) * H
                pred_w = nw * W
                pred_h = nh * H
                
                # ğŸ’¡ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ì— ì €ì¥
                predictions[meta[i]["query_id"]] = (pred_x, pred_y, pred_w, pred_h)

    # ğŸ’¡ [í•µì‹¬] sample_submission.csv  ìˆœì„œëŒ€ë¡œ ê²°ê³¼ ë§¤í•‘
    final_rows = []
    for idx, row in sub_df.iterrows():
        query_id = row["query_id"]
        pred_coords = predictions.get(query_id, (0, 0, 0, 0)) # ğŸ’¡ ë§¤ì¹­ëœ ì˜ˆì¸¡ê°’, ì—†ìœ¼ë©´ (0,0,0,0)
        
        final_rows.append({
            "query_id": query_id,
            "query_text": row["query_text"],
            "pred_x": pred_coords[0],
            "pred_y": pred_coords[1],
            "pred_w": pred_coords[2],
            "pred_h": pred_coords[3],
        })

    os.makedirs(os.path.dirname(args.out_csv), exist_ok=True)
    df = pd.DataFrame(final_rows, columns=["query_id", "query_text", "pred_x", "pred_y", "pred_w", "pred_h"])
    df.to_csv(args.out_csv, index=False, encoding="utf-8-sig")
    print(f"âœ… [ì €ì¥ ì™„ë£Œ] ìµœì¢… ì œì¶œ íŒŒì¼ ìƒì„± (ìˆœì„œ ë³´ì¥ë¨): {args.out_csv}")


# --- [5. CLI] ---
def get_args():
    ap = argparse.ArgumentParser()
    # ğŸ’¡ [ìˆ˜ì •] --json_dir ëŒ€ì‹  --submission_csv ì‚¬ìš©
    ap.add_argument("--submission_csv", type=str, required=True, help="ì •ë‹µ ìˆœì„œê°€ ì •ì˜ëœ sample_submission.csv  ê²½ë¡œ")
    ap.add_argument("--jpg_dir", type=str, required=True, help="Test JPG ì´ë¯¸ì§€ í´ë”")
    ap.add_argument("--ckpt", type=str, required=True, help="í•™ìŠµëœ .pth ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ")
    
    ap.add_argument("--batch_size", type=int, default=CFG.BATCH_SIZE) 
    ap.add_argument("--num_workers", type=int, default=CFG.NUM_WORKERS)
    ap.add_argument("--out_csv", type=str, default="./outputs/preds/test_pred.csv", help="ì¶œë ¥ CSV íŒŒì¼ ê²½ë¡œ")
    return ap.parse_args()

def main():
    seed_everything(CFG.SEED)
    args = get_args()
    predict_loop(args)

if __name__ == "__main__":
    main()
